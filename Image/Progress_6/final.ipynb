{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vopo\\anaconda3\\envs\\project1\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vopo\\anaconda3\\envs\\project1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face 1: neutral with probability 0.8946856260299683\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# 定义情绪分类模型\n",
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=7):  # 假设有7种情绪\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.densenet = models.densenet121(pretrained=True)\n",
    "        num_ftrs = self.densenet.classifier.in_features\n",
    "        self.densenet.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)\n",
    "\n",
    "# 加载模型\n",
    "model = EmotionClassifier().to('cuda')\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "# 定义图片的预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 预测情绪的函数\n",
    "def predict_emotion(model, face_img):\n",
    "    image_tensor = transform(face_img).unsqueeze(0).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        return probabilities.cpu().numpy()\n",
    "\n",
    "# 人脸检测和裁剪\n",
    "def detect_and_crop_face(image_path):\n",
    "    mtcnn = MTCNN(keep_all=True, device='cuda')\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    boxes, _ = mtcnn.detect(img)\n",
    "    if boxes is not None and len(boxes) > 0:\n",
    "        # 计算每个框的面积\n",
    "        areas = [(box[2]-box[0])*(box[3]-box[1]) for box in boxes]\n",
    "        # 选择面积最大的框\n",
    "        max_area_idx = np.argmax(areas)\n",
    "        box = boxes[max_area_idx].astype(int)\n",
    "        # 裁剪面积最大的人脸\n",
    "        cropped_face = img[box[1]:box[3], box[0]:box[2]]\n",
    "        return [cropped_face]  # 以列表形式返回，保持后续处理的一致性\n",
    "    return None\n",
    "\n",
    "\n",
    "# 整合流程\n",
    "image_path = '5.png'  # 替换为你的图片路径\n",
    "cropped_faces = detect_and_crop_face(image_path)\n",
    "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
    "\n",
    "if cropped_faces is not None:\n",
    "    for i, face in enumerate(cropped_faces):\n",
    "        face_img = Image.fromarray(face)\n",
    "        probabilities = predict_emotion(model, face_img)\n",
    "        predicted_emotion = emotion_labels[probabilities.argmax()]\n",
    "        print(f\"Face {i+1}: {predicted_emotion} with probability {probabilities.max()}\")\n",
    "        # 显示或保存裁剪的人脸及其情绪预测\n",
    "        # face_img.show()\n",
    "        # face_img.save(f'cropped_face_{i}_{predicted_emotion}.png')\n",
    "else:\n",
    "    print(\"No faces were detected.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
